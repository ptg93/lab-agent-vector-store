{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "efad6479-7fb1-40c4-8610-8963f8de307f",
   "metadata": {},
   "source": [
    "# Lab | Agent & Vector store\n",
    "\n",
    "**Change the state union dataset and replicate this lab by updating the prompts accordingly.**\n",
    "\n",
    "One such dataset is the [sonnets.txt](https://github.com/martin-gorner/tensorflow-rnn-shakespeare/blob/master/shakespeare/sonnets.txt) dataset or any other data of your choice from the same git."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "68b24990",
   "metadata": {},
   "source": [
    "# Combine agents and vector stores\n",
    "\n",
    "This notebook covers how to combine agents and vector stores. The use case for this is that you've ingested your data into a vector store and want to interact with it in an agentic manner.\n",
    "\n",
    "The recommended method for doing so is to create a `RetrievalQA` and then use that as a tool in the overall agent. Let's take a look at doing this below. You can do this with multiple different vector DBs, and use the agent as a way to route between them. There are two different ways of doing this - you can either let the agent use the vector stores as normal tools, or you can set `return_direct=True` to really just use the agent as a router."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9b22020a",
   "metadata": {},
   "source": [
    "## Create the vector store"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "12df91e0-7322-43c2-96cd-0159d017a1e1",
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting chromadb\n",
      "  Downloading chromadb-0.5.3-py3-none-any.whl.metadata (6.8 kB)\n",
      "Collecting build>=1.0.3 (from chromadb)\n",
      "  Downloading build-1.2.1-py3-none-any.whl.metadata (4.3 kB)\n",
      "Requirement already satisfied: requests>=2.28 in c:\\users\\pedro\\anaconda3\\envs\\pytorchcudaenv\\lib\\site-packages (from chromadb) (2.32.3)\n",
      "Requirement already satisfied: pydantic>=1.9 in c:\\users\\pedro\\anaconda3\\envs\\pytorchcudaenv\\lib\\site-packages (from chromadb) (2.7.4)\n",
      "Collecting chroma-hnswlib==0.7.3 (from chromadb)\n",
      "  Downloading chroma_hnswlib-0.7.3-cp39-cp39-win_amd64.whl.metadata (262 bytes)\n",
      "Requirement already satisfied: fastapi>=0.95.2 in c:\\users\\pedro\\anaconda3\\envs\\pytorchcudaenv\\lib\\site-packages (from chromadb) (0.111.0)\n",
      "Requirement already satisfied: uvicorn>=0.18.3 in c:\\users\\pedro\\anaconda3\\envs\\pytorchcudaenv\\lib\\site-packages (from uvicorn[standard]>=0.18.3->chromadb) (0.30.1)\n",
      "Requirement already satisfied: numpy<2.0.0,>=1.22.5 in c:\\users\\pedro\\anaconda3\\envs\\pytorchcudaenv\\lib\\site-packages (from chromadb) (1.24.3)\n",
      "Collecting posthog>=2.4.0 (from chromadb)\n",
      "  Downloading posthog-3.5.0-py2.py3-none-any.whl.metadata (2.0 kB)\n",
      "Requirement already satisfied: typing-extensions>=4.5.0 in c:\\users\\pedro\\anaconda3\\envs\\pytorchcudaenv\\lib\\site-packages (from chromadb) (4.11.0)\n",
      "Collecting onnxruntime>=1.14.1 (from chromadb)\n",
      "  Downloading onnxruntime-1.18.1-cp39-cp39-win_amd64.whl.metadata (4.5 kB)\n",
      "Collecting opentelemetry-api>=1.2.0 (from chromadb)\n",
      "  Downloading opentelemetry_api-1.25.0-py3-none-any.whl.metadata (1.4 kB)\n",
      "Collecting opentelemetry-exporter-otlp-proto-grpc>=1.2.0 (from chromadb)\n",
      "  Downloading opentelemetry_exporter_otlp_proto_grpc-1.25.0-py3-none-any.whl.metadata (2.2 kB)\n",
      "Collecting opentelemetry-instrumentation-fastapi>=0.41b0 (from chromadb)\n",
      "  Downloading opentelemetry_instrumentation_fastapi-0.46b0-py3-none-any.whl.metadata (2.0 kB)\n",
      "Collecting opentelemetry-sdk>=1.2.0 (from chromadb)\n",
      "  Downloading opentelemetry_sdk-1.25.0-py3-none-any.whl.metadata (1.4 kB)\n",
      "Requirement already satisfied: tokenizers>=0.13.2 in c:\\users\\pedro\\appdata\\roaming\\python\\python39\\site-packages (from chromadb) (0.19.1)\n",
      "Collecting pypika>=0.48.9 (from chromadb)\n",
      "  Downloading PyPika-0.48.9.tar.gz (67 kB)\n",
      "     ---------------------------------------- 0.0/67.3 kB ? eta -:--:--\n",
      "     ---------------------------------------- 67.3/67.3 kB 3.6 MB/s eta 0:00:00\n",
      "  Installing build dependencies: started\n",
      "  Installing build dependencies: finished with status 'done'\n",
      "  Getting requirements to build wheel: started\n",
      "  Getting requirements to build wheel: finished with status 'done'\n",
      "  Preparing metadata (pyproject.toml): started\n",
      "  Preparing metadata (pyproject.toml): finished with status 'done'\n",
      "Requirement already satisfied: tqdm>=4.65.0 in c:\\users\\pedro\\anaconda3\\envs\\pytorchcudaenv\\lib\\site-packages (from chromadb) (4.66.4)\n",
      "Requirement already satisfied: overrides>=7.3.1 in c:\\users\\pedro\\anaconda3\\envs\\pytorchcudaenv\\lib\\site-packages (from chromadb) (7.4.0)\n",
      "Requirement already satisfied: importlib-resources in c:\\users\\pedro\\anaconda3\\envs\\pytorchcudaenv\\lib\\site-packages (from chromadb) (6.4.0)\n",
      "Requirement already satisfied: grpcio>=1.58.0 in c:\\users\\pedro\\anaconda3\\envs\\pytorchcudaenv\\lib\\site-packages (from chromadb) (1.64.1)\n",
      "Collecting bcrypt>=4.0.1 (from chromadb)\n",
      "  Downloading bcrypt-4.1.3-cp39-abi3-win_amd64.whl.metadata (9.8 kB)\n",
      "Requirement already satisfied: typer>=0.9.0 in c:\\users\\pedro\\anaconda3\\envs\\pytorchcudaenv\\lib\\site-packages (from chromadb) (0.12.3)\n",
      "Collecting kubernetes>=28.1.0 (from chromadb)\n",
      "  Downloading kubernetes-30.1.0-py2.py3-none-any.whl.metadata (1.5 kB)\n",
      "Requirement already satisfied: tenacity>=8.2.3 in c:\\users\\pedro\\anaconda3\\envs\\pytorchcudaenv\\lib\\site-packages (from chromadb) (8.4.2)\n",
      "Requirement already satisfied: PyYAML>=6.0.0 in c:\\users\\pedro\\anaconda3\\envs\\pytorchcudaenv\\lib\\site-packages (from chromadb) (6.0.1)\n",
      "Collecting mmh3>=4.0.1 (from chromadb)\n",
      "  Downloading mmh3-4.1.0-cp39-cp39-win_amd64.whl.metadata (13 kB)\n",
      "Requirement already satisfied: orjson>=3.9.12 in c:\\users\\pedro\\anaconda3\\envs\\pytorchcudaenv\\lib\\site-packages (from chromadb) (3.10.5)\n",
      "Requirement already satisfied: httpx>=0.27.0 in c:\\users\\pedro\\anaconda3\\envs\\pytorchcudaenv\\lib\\site-packages (from chromadb) (0.27.0)\n",
      "Requirement already satisfied: packaging>=19.1 in c:\\users\\pedro\\anaconda3\\envs\\pytorchcudaenv\\lib\\site-packages (from build>=1.0.3->chromadb) (23.2)\n",
      "Collecting pyproject_hooks (from build>=1.0.3->chromadb)\n",
      "  Downloading pyproject_hooks-1.1.0-py3-none-any.whl.metadata (1.3 kB)\n",
      "Requirement already satisfied: colorama in c:\\users\\pedro\\appdata\\roaming\\python\\python39\\site-packages (from build>=1.0.3->chromadb) (0.4.3)\n",
      "Requirement already satisfied: importlib-metadata>=4.6 in c:\\users\\pedro\\anaconda3\\envs\\pytorchcudaenv\\lib\\site-packages (from build>=1.0.3->chromadb) (7.0.1)\n",
      "Requirement already satisfied: tomli>=1.1.0 in c:\\users\\pedro\\anaconda3\\envs\\pytorchcudaenv\\lib\\site-packages (from build>=1.0.3->chromadb) (2.0.1)\n",
      "Requirement already satisfied: starlette<0.38.0,>=0.37.2 in c:\\users\\pedro\\anaconda3\\envs\\pytorchcudaenv\\lib\\site-packages (from fastapi>=0.95.2->chromadb) (0.37.2)\n",
      "Requirement already satisfied: fastapi-cli>=0.0.2 in c:\\users\\pedro\\anaconda3\\envs\\pytorchcudaenv\\lib\\site-packages (from fastapi>=0.95.2->chromadb) (0.0.4)\n",
      "Requirement already satisfied: jinja2>=2.11.2 in c:\\users\\pedro\\anaconda3\\envs\\pytorchcudaenv\\lib\\site-packages (from fastapi>=0.95.2->chromadb) (3.1.4)\n",
      "Requirement already satisfied: python-multipart>=0.0.7 in c:\\users\\pedro\\anaconda3\\envs\\pytorchcudaenv\\lib\\site-packages (from fastapi>=0.95.2->chromadb) (0.0.9)\n",
      "Requirement already satisfied: ujson!=4.0.2,!=4.1.0,!=4.2.0,!=4.3.0,!=5.0.0,!=5.1.0,>=4.0.1 in c:\\users\\pedro\\anaconda3\\envs\\pytorchcudaenv\\lib\\site-packages (from fastapi>=0.95.2->chromadb) (5.10.0)\n",
      "Requirement already satisfied: email_validator>=2.0.0 in c:\\users\\pedro\\anaconda3\\envs\\pytorchcudaenv\\lib\\site-packages (from fastapi>=0.95.2->chromadb) (2.2.0)\n",
      "Requirement already satisfied: anyio in c:\\users\\pedro\\anaconda3\\envs\\pytorchcudaenv\\lib\\site-packages (from httpx>=0.27.0->chromadb) (4.2.0)\n",
      "Requirement already satisfied: certifi in c:\\users\\pedro\\appdata\\roaming\\python\\python39\\site-packages (from httpx>=0.27.0->chromadb) (2019.11.28)\n",
      "Requirement already satisfied: httpcore==1.* in c:\\users\\pedro\\anaconda3\\envs\\pytorchcudaenv\\lib\\site-packages (from httpx>=0.27.0->chromadb) (1.0.5)\n",
      "Requirement already satisfied: idna in c:\\users\\pedro\\appdata\\roaming\\python\\python39\\site-packages (from httpx>=0.27.0->chromadb) (2.8)\n",
      "Requirement already satisfied: sniffio in c:\\users\\pedro\\anaconda3\\envs\\pytorchcudaenv\\lib\\site-packages (from httpx>=0.27.0->chromadb) (1.3.0)\n",
      "Requirement already satisfied: h11<0.15,>=0.13 in c:\\users\\pedro\\anaconda3\\envs\\pytorchcudaenv\\lib\\site-packages (from httpcore==1.*->httpx>=0.27.0->chromadb) (0.14.0)\n",
      "Requirement already satisfied: six>=1.9.0 in c:\\users\\pedro\\anaconda3\\envs\\pytorchcudaenv\\lib\\site-packages (from kubernetes>=28.1.0->chromadb) (1.16.0)\n",
      "Requirement already satisfied: python-dateutil>=2.5.3 in c:\\users\\pedro\\anaconda3\\envs\\pytorchcudaenv\\lib\\site-packages (from kubernetes>=28.1.0->chromadb) (2.9.0.post0)\n",
      "Collecting google-auth>=1.0.1 (from kubernetes>=28.1.0->chromadb)\n",
      "  Downloading google_auth-2.31.0-py2.py3-none-any.whl.metadata (4.7 kB)\n",
      "Requirement already satisfied: websocket-client!=0.40.0,!=0.41.*,!=0.42.*,>=0.32.0 in c:\\users\\pedro\\anaconda3\\envs\\pytorchcudaenv\\lib\\site-packages (from kubernetes>=28.1.0->chromadb) (1.8.0)\n",
      "Collecting requests-oauthlib (from kubernetes>=28.1.0->chromadb)\n",
      "  Using cached requests_oauthlib-2.0.0-py2.py3-none-any.whl.metadata (11 kB)\n",
      "Collecting oauthlib>=3.2.2 (from kubernetes>=28.1.0->chromadb)\n",
      "  Using cached oauthlib-3.2.2-py3-none-any.whl.metadata (7.5 kB)\n",
      "Requirement already satisfied: urllib3>=1.24.2 in c:\\users\\pedro\\anaconda3\\envs\\pytorchcudaenv\\lib\\site-packages (from kubernetes>=28.1.0->chromadb) (2.2.1)\n",
      "Collecting coloredlogs (from onnxruntime>=1.14.1->chromadb)\n",
      "  Downloading coloredlogs-15.0.1-py2.py3-none-any.whl.metadata (12 kB)\n",
      "Requirement already satisfied: flatbuffers in c:\\users\\pedro\\anaconda3\\envs\\pytorchcudaenv\\lib\\site-packages (from onnxruntime>=1.14.1->chromadb) (24.3.25)\n",
      "Requirement already satisfied: protobuf in c:\\users\\pedro\\anaconda3\\envs\\pytorchcudaenv\\lib\\site-packages (from onnxruntime>=1.14.1->chromadb) (4.25.3)\n",
      "Requirement already satisfied: sympy in c:\\users\\pedro\\anaconda3\\envs\\pytorchcudaenv\\lib\\site-packages (from onnxruntime>=1.14.1->chromadb) (1.12)\n",
      "Collecting deprecated>=1.2.6 (from opentelemetry-api>=1.2.0->chromadb)\n",
      "  Downloading Deprecated-1.2.14-py2.py3-none-any.whl.metadata (5.4 kB)\n",
      "Collecting googleapis-common-protos~=1.52 (from opentelemetry-exporter-otlp-proto-grpc>=1.2.0->chromadb)\n",
      "  Downloading googleapis_common_protos-1.63.2-py2.py3-none-any.whl.metadata (1.5 kB)\n",
      "Collecting opentelemetry-exporter-otlp-proto-common==1.25.0 (from opentelemetry-exporter-otlp-proto-grpc>=1.2.0->chromadb)\n",
      "  Downloading opentelemetry_exporter_otlp_proto_common-1.25.0-py3-none-any.whl.metadata (1.7 kB)\n",
      "Collecting opentelemetry-proto==1.25.0 (from opentelemetry-exporter-otlp-proto-grpc>=1.2.0->chromadb)\n",
      "  Downloading opentelemetry_proto-1.25.0-py3-none-any.whl.metadata (2.2 kB)\n",
      "Collecting opentelemetry-instrumentation-asgi==0.46b0 (from opentelemetry-instrumentation-fastapi>=0.41b0->chromadb)\n",
      "  Downloading opentelemetry_instrumentation_asgi-0.46b0-py3-none-any.whl.metadata (1.9 kB)\n",
      "Collecting opentelemetry-instrumentation==0.46b0 (from opentelemetry-instrumentation-fastapi>=0.41b0->chromadb)\n",
      "  Downloading opentelemetry_instrumentation-0.46b0-py3-none-any.whl.metadata (6.1 kB)\n",
      "Collecting opentelemetry-semantic-conventions==0.46b0 (from opentelemetry-instrumentation-fastapi>=0.41b0->chromadb)\n",
      "  Downloading opentelemetry_semantic_conventions-0.46b0-py3-none-any.whl.metadata (2.3 kB)\n",
      "Collecting opentelemetry-util-http==0.46b0 (from opentelemetry-instrumentation-fastapi>=0.41b0->chromadb)\n",
      "  Downloading opentelemetry_util_http-0.46b0-py3-none-any.whl.metadata (2.4 kB)\n",
      "Requirement already satisfied: setuptools>=16.0 in c:\\users\\pedro\\anaconda3\\envs\\pytorchcudaenv\\lib\\site-packages (from opentelemetry-instrumentation==0.46b0->opentelemetry-instrumentation-fastapi>=0.41b0->chromadb) (69.5.1)\n",
      "Requirement already satisfied: wrapt<2.0.0,>=1.0.0 in c:\\users\\pedro\\appdata\\roaming\\python\\python39\\site-packages (from opentelemetry-instrumentation==0.46b0->opentelemetry-instrumentation-fastapi>=0.41b0->chromadb) (1.11.2)\n",
      "Collecting asgiref~=3.0 (from opentelemetry-instrumentation-asgi==0.46b0->opentelemetry-instrumentation-fastapi>=0.41b0->chromadb)\n",
      "  Downloading asgiref-3.8.1-py3-none-any.whl.metadata (9.3 kB)\n",
      "Collecting monotonic>=1.5 (from posthog>=2.4.0->chromadb)\n",
      "  Downloading monotonic-1.6-py2.py3-none-any.whl.metadata (1.5 kB)\n",
      "Collecting backoff>=1.10.0 (from posthog>=2.4.0->chromadb)\n",
      "  Downloading backoff-2.2.1-py3-none-any.whl.metadata (14 kB)\n",
      "Requirement already satisfied: annotated-types>=0.4.0 in c:\\users\\pedro\\anaconda3\\envs\\pytorchcudaenv\\lib\\site-packages (from pydantic>=1.9->chromadb) (0.7.0)\n",
      "Requirement already satisfied: pydantic-core==2.18.4 in c:\\users\\pedro\\anaconda3\\envs\\pytorchcudaenv\\lib\\site-packages (from pydantic>=1.9->chromadb) (2.18.4)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in c:\\users\\pedro\\anaconda3\\envs\\pytorchcudaenv\\lib\\site-packages (from requests>=2.28->chromadb) (2.0.4)\n",
      "Requirement already satisfied: huggingface-hub<1.0,>=0.16.4 in c:\\users\\pedro\\appdata\\roaming\\python\\python39\\site-packages (from tokenizers>=0.13.2->chromadb) (0.23.4)\n",
      "Requirement already satisfied: click>=8.0.0 in c:\\users\\pedro\\appdata\\roaming\\python\\python39\\site-packages (from typer>=0.9.0->chromadb) (8.1.7)\n",
      "Requirement already satisfied: shellingham>=1.3.0 in c:\\users\\pedro\\anaconda3\\envs\\pytorchcudaenv\\lib\\site-packages (from typer>=0.9.0->chromadb) (1.5.4)\n",
      "Requirement already satisfied: rich>=10.11.0 in c:\\users\\pedro\\anaconda3\\envs\\pytorchcudaenv\\lib\\site-packages (from typer>=0.9.0->chromadb) (13.7.1)\n",
      "Requirement already satisfied: httptools>=0.5.0 in c:\\users\\pedro\\anaconda3\\envs\\pytorchcudaenv\\lib\\site-packages (from uvicorn[standard]>=0.18.3->chromadb) (0.6.1)\n",
      "Requirement already satisfied: python-dotenv>=0.13 in c:\\users\\pedro\\anaconda3\\envs\\pytorchcudaenv\\lib\\site-packages (from uvicorn[standard]>=0.18.3->chromadb) (1.0.1)\n",
      "Requirement already satisfied: watchfiles>=0.13 in c:\\users\\pedro\\anaconda3\\envs\\pytorchcudaenv\\lib\\site-packages (from uvicorn[standard]>=0.18.3->chromadb) (0.22.0)\n",
      "Requirement already satisfied: websockets>=10.4 in c:\\users\\pedro\\anaconda3\\envs\\pytorchcudaenv\\lib\\site-packages (from uvicorn[standard]>=0.18.3->chromadb) (12.0)\n",
      "Requirement already satisfied: zipp>=3.1.0 in c:\\users\\pedro\\anaconda3\\envs\\pytorchcudaenv\\lib\\site-packages (from importlib-resources->chromadb) (3.17.0)\n",
      "Requirement already satisfied: dnspython>=2.0.0 in c:\\users\\pedro\\anaconda3\\envs\\pytorchcudaenv\\lib\\site-packages (from email_validator>=2.0.0->fastapi>=0.95.2->chromadb) (2.6.1)\n",
      "Collecting cachetools<6.0,>=2.0.0 (from google-auth>=1.0.1->kubernetes>=28.1.0->chromadb)\n",
      "  Using cached cachetools-5.3.3-py3-none-any.whl.metadata (5.3 kB)\n",
      "Collecting pyasn1-modules>=0.2.1 (from google-auth>=1.0.1->kubernetes>=28.1.0->chromadb)\n",
      "  Using cached pyasn1_modules-0.4.0-py3-none-any.whl.metadata (3.4 kB)\n",
      "Collecting rsa<5,>=3.1.4 (from google-auth>=1.0.1->kubernetes>=28.1.0->chromadb)\n",
      "  Using cached rsa-4.9-py3-none-any.whl.metadata (4.2 kB)\n",
      "Requirement already satisfied: filelock in c:\\users\\pedro\\anaconda3\\envs\\pytorchcudaenv\\lib\\site-packages (from huggingface-hub<1.0,>=0.16.4->tokenizers>=0.13.2->chromadb) (3.13.1)\n",
      "Requirement already satisfied: fsspec>=2023.5.0 in c:\\users\\pedro\\appdata\\roaming\\python\\python39\\site-packages (from huggingface-hub<1.0,>=0.16.4->tokenizers>=0.13.2->chromadb) (2024.5.0)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in c:\\users\\pedro\\anaconda3\\envs\\pytorchcudaenv\\lib\\site-packages (from jinja2>=2.11.2->fastapi>=0.95.2->chromadb) (2.1.3)\n",
      "Requirement already satisfied: markdown-it-py>=2.2.0 in c:\\users\\pedro\\anaconda3\\envs\\pytorchcudaenv\\lib\\site-packages (from rich>=10.11.0->typer>=0.9.0->chromadb) (3.0.0)\n",
      "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in c:\\users\\pedro\\anaconda3\\envs\\pytorchcudaenv\\lib\\site-packages (from rich>=10.11.0->typer>=0.9.0->chromadb) (2.15.1)\n",
      "Requirement already satisfied: exceptiongroup>=1.0.2 in c:\\users\\pedro\\anaconda3\\envs\\pytorchcudaenv\\lib\\site-packages (from anyio->httpx>=0.27.0->chromadb) (1.2.0)\n",
      "Collecting humanfriendly>=9.1 (from coloredlogs->onnxruntime>=1.14.1->chromadb)\n",
      "  Downloading humanfriendly-10.0-py2.py3-none-any.whl.metadata (9.2 kB)\n",
      "Requirement already satisfied: mpmath>=0.19 in c:\\users\\pedro\\anaconda3\\envs\\pytorchcudaenv\\lib\\site-packages (from sympy->onnxruntime>=1.14.1->chromadb) (1.3.0)\n",
      "Collecting pyreadline3 (from humanfriendly>=9.1->coloredlogs->onnxruntime>=1.14.1->chromadb)\n",
      "  Downloading pyreadline3-3.4.1-py3-none-any.whl.metadata (2.0 kB)\n",
      "Requirement already satisfied: mdurl~=0.1 in c:\\users\\pedro\\anaconda3\\envs\\pytorchcudaenv\\lib\\site-packages (from markdown-it-py>=2.2.0->rich>=10.11.0->typer>=0.9.0->chromadb) (0.1.2)\n",
      "Collecting pyasn1<0.7.0,>=0.4.6 (from pyasn1-modules>=0.2.1->google-auth>=1.0.1->kubernetes>=28.1.0->chromadb)\n",
      "  Using cached pyasn1-0.6.0-py2.py3-none-any.whl.metadata (8.3 kB)\n",
      "Downloading chromadb-0.5.3-py3-none-any.whl (559 kB)\n",
      "   ---------------------------------------- 0.0/559.5 kB ? eta -:--:--\n",
      "   --------------------------------------- 559.5/559.5 kB 17.2 MB/s eta 0:00:00\n",
      "Downloading chroma_hnswlib-0.7.3-cp39-cp39-win_amd64.whl (150 kB)\n",
      "   ---------------------------------------- 0.0/150.6 kB ? eta -:--:--\n",
      "   ---------------------------------------- 150.6/150.6 kB 9.4 MB/s eta 0:00:00\n",
      "Downloading bcrypt-4.1.3-cp39-abi3-win_amd64.whl (158 kB)\n",
      "   ---------------------------------------- 0.0/158.1 kB ? eta -:--:--\n",
      "   ---------------------------------------- 158.1/158.1 kB 9.2 MB/s eta 0:00:00\n",
      "Downloading build-1.2.1-py3-none-any.whl (21 kB)\n",
      "Downloading kubernetes-30.1.0-py2.py3-none-any.whl (1.7 MB)\n",
      "   ---------------------------------------- 0.0/1.7 MB ? eta -:--:--\n",
      "   --------------------------------- ------ 1.4/1.7 MB 44.2 MB/s eta 0:00:01\n",
      "   ---------------------------------------- 1.7/1.7 MB 36.1 MB/s eta 0:00:00\n",
      "Downloading mmh3-4.1.0-cp39-cp39-win_amd64.whl (31 kB)\n",
      "Downloading onnxruntime-1.18.1-cp39-cp39-win_amd64.whl (5.6 MB)\n",
      "   ---------------------------------------- 0.0/5.6 MB ? eta -:--:--\n",
      "   ----------- ---------------------------- 1.6/5.6 MB 33.1 MB/s eta 0:00:01\n",
      "   --------------- ------------------------ 2.2/5.6 MB 23.6 MB/s eta 0:00:01\n",
      "   -------------------- ------------------- 2.8/5.6 MB 20.0 MB/s eta 0:00:01\n",
      "   ------------------------ --------------- 3.4/5.6 MB 18.2 MB/s eta 0:00:01\n",
      "   ---------------------------- ----------- 4.0/5.6 MB 17.1 MB/s eta 0:00:01\n",
      "   -------------------------------- ------- 4.6/5.6 MB 16.3 MB/s eta 0:00:01\n",
      "   ------------------------------------- -- 5.2/5.6 MB 15.7 MB/s eta 0:00:01\n",
      "   -------------------------------------- - 5.4/5.6 MB 14.4 MB/s eta 0:00:01\n",
      "   ---------------------------------------  5.5/5.6 MB 13.1 MB/s eta 0:00:01\n",
      "   ---------------------------------------- 5.6/5.6 MB 12.8 MB/s eta 0:00:00\n",
      "Downloading opentelemetry_api-1.25.0-py3-none-any.whl (59 kB)\n",
      "   ---------------------------------------- 0.0/59.9 kB ? eta -:--:--\n",
      "   ---------------------------------------- 59.9/59.9 kB ? eta 0:00:00\n",
      "Downloading opentelemetry_exporter_otlp_proto_grpc-1.25.0-py3-none-any.whl (18 kB)\n",
      "Downloading opentelemetry_exporter_otlp_proto_common-1.25.0-py3-none-any.whl (17 kB)\n",
      "Downloading opentelemetry_proto-1.25.0-py3-none-any.whl (52 kB)\n",
      "   ---------------------------------------- 0.0/52.5 kB ? eta -:--:--\n",
      "   ---------------------------------------- 52.5/52.5 kB 2.6 MB/s eta 0:00:00\n",
      "Downloading opentelemetry_instrumentation_fastapi-0.46b0-py3-none-any.whl (11 kB)\n",
      "Downloading opentelemetry_instrumentation-0.46b0-py3-none-any.whl (29 kB)\n",
      "Downloading opentelemetry_instrumentation_asgi-0.46b0-py3-none-any.whl (14 kB)\n",
      "Downloading opentelemetry_semantic_conventions-0.46b0-py3-none-any.whl (130 kB)\n",
      "   ---------------------------------------- 0.0/130.5 kB ? eta -:--:--\n",
      "   ---------------------------------------- 130.5/130.5 kB 7.5 MB/s eta 0:00:00\n",
      "Downloading opentelemetry_util_http-0.46b0-py3-none-any.whl (6.9 kB)\n",
      "Downloading opentelemetry_sdk-1.25.0-py3-none-any.whl (107 kB)\n",
      "   ---------------------------------------- 0.0/107.0 kB ? eta -:--:--\n",
      "   ---------------------------------------- 107.0/107.0 kB 6.0 MB/s eta 0:00:00\n",
      "Downloading posthog-3.5.0-py2.py3-none-any.whl (41 kB)\n",
      "   ---------------------------------------- 0.0/41.3 kB ? eta -:--:--\n",
      "   ---------------------------------------- 41.3/41.3 kB ? eta 0:00:00\n",
      "Downloading backoff-2.2.1-py3-none-any.whl (15 kB)\n",
      "Downloading Deprecated-1.2.14-py2.py3-none-any.whl (9.6 kB)\n",
      "Downloading google_auth-2.31.0-py2.py3-none-any.whl (194 kB)\n",
      "   ---------------------------------------- 0.0/194.6 kB ? eta -:--:--\n",
      "   ---------------------------------------- 194.6/194.6 kB ? eta 0:00:00\n",
      "Downloading googleapis_common_protos-1.63.2-py2.py3-none-any.whl (220 kB)\n",
      "   ---------------------------------------- 0.0/220.0 kB ? eta -:--:--\n",
      "   ---------------------------------------- 220.0/220.0 kB ? eta 0:00:00\n",
      "Downloading monotonic-1.6-py2.py3-none-any.whl (8.2 kB)\n",
      "Using cached oauthlib-3.2.2-py3-none-any.whl (151 kB)\n",
      "Downloading coloredlogs-15.0.1-py2.py3-none-any.whl (46 kB)\n",
      "   ---------------------------------------- 0.0/46.0 kB ? eta -:--:--\n",
      "   ---------------------------------------- 46.0/46.0 kB ? eta 0:00:00\n",
      "Downloading pyproject_hooks-1.1.0-py3-none-any.whl (9.2 kB)\n",
      "Using cached requests_oauthlib-2.0.0-py2.py3-none-any.whl (24 kB)\n",
      "Downloading asgiref-3.8.1-py3-none-any.whl (23 kB)\n",
      "Using cached cachetools-5.3.3-py3-none-any.whl (9.3 kB)\n",
      "Downloading humanfriendly-10.0-py2.py3-none-any.whl (86 kB)\n",
      "   ---------------------------------------- 0.0/86.8 kB ? eta -:--:--\n",
      "   ---------------------------------------- 86.8/86.8 kB ? eta 0:00:00\n",
      "Using cached pyasn1_modules-0.4.0-py3-none-any.whl (181 kB)\n",
      "Using cached rsa-4.9-py3-none-any.whl (34 kB)\n",
      "Using cached pyasn1-0.6.0-py2.py3-none-any.whl (85 kB)\n",
      "Downloading pyreadline3-3.4.1-py3-none-any.whl (95 kB)\n",
      "   ---------------------------------------- 0.0/95.2 kB ? eta -:--:--\n",
      "   ---------------------------------------- 95.2/95.2 kB ? eta 0:00:00\n",
      "Building wheels for collected packages: pypika\n",
      "  Building wheel for pypika (pyproject.toml): started\n",
      "  Building wheel for pypika (pyproject.toml): finished with status 'done'\n",
      "  Created wheel for pypika: filename=PyPika-0.48.9-py2.py3-none-any.whl size=53835 sha256=fe087046525c47b1c8142a7d5a6625f5f6fad6e015125572ebc07af1eee16811\n",
      "  Stored in directory: c:\\users\\pedro\\appdata\\local\\pip\\cache\\wheels\\f7\\02\\64\\d541eac67ec459309d1fb19e727f58ecf7ffb4a8bf42d4cfe5\n",
      "Successfully built pypika\n",
      "Installing collected packages: pyreadline3, pypika, monotonic, mmh3, pyproject_hooks, pyasn1, opentelemetry-util-http, opentelemetry-proto, oauthlib, humanfriendly, googleapis-common-protos, deprecated, chroma-hnswlib, cachetools, bcrypt, backoff, asgiref, rsa, requests-oauthlib, pyasn1-modules, posthog, opentelemetry-exporter-otlp-proto-common, opentelemetry-api, coloredlogs, build, opentelemetry-semantic-conventions, opentelemetry-instrumentation, onnxruntime, google-auth, opentelemetry-sdk, opentelemetry-instrumentation-asgi, kubernetes, opentelemetry-instrumentation-fastapi, opentelemetry-exporter-otlp-proto-grpc, chromadb\n",
      "Successfully installed asgiref-3.8.1 backoff-2.2.1 bcrypt-4.1.3 build-1.2.1 cachetools-5.3.3 chroma-hnswlib-0.7.3 chromadb-0.5.3 coloredlogs-15.0.1 deprecated-1.2.14 google-auth-2.31.0 googleapis-common-protos-1.63.2 humanfriendly-10.0 kubernetes-30.1.0 mmh3-4.1.0 monotonic-1.6 oauthlib-3.2.2 onnxruntime-1.18.1 opentelemetry-api-1.25.0 opentelemetry-exporter-otlp-proto-common-1.25.0 opentelemetry-exporter-otlp-proto-grpc-1.25.0 opentelemetry-instrumentation-0.46b0 opentelemetry-instrumentation-asgi-0.46b0 opentelemetry-instrumentation-fastapi-0.46b0 opentelemetry-proto-1.25.0 opentelemetry-sdk-1.25.0 opentelemetry-semantic-conventions-0.46b0 opentelemetry-util-http-0.46b0 posthog-3.5.0 pyasn1-0.6.0 pyasn1-modules-0.4.0 pypika-0.48.9 pyproject_hooks-1.1.0 pyreadline3-3.4.1 requests-oauthlib-2.0.0 rsa-4.9\n"
     ]
    }
   ],
   "source": [
    "#!pip install chromadb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "2868cff1-a3ef-426f-b8d7-7fe89047a5b7",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from langchain.chains import RetrievalQA\n",
    "from langchain_community.vectorstores import Chroma\n",
    "from langchain_openai import OpenAI, OpenAIEmbeddings\n",
    "from langchain_text_splitters import CharacterTextSplitter\n",
    "from langchain_community.document_loaders import TextLoader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "aeff3a2d-b0cc-429f-a34c-4381d71f1a5f",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import os\n",
    "from dotenv import load_dotenv, find_dotenv\n",
    "_ = load_dotenv(find_dotenv())\n",
    "\n",
    "OPENAI_API_KEY  = os.getenv('OPENAI_API_KEY')\n",
    "HUGGINGFACEHUB_API_TOKEN = os.getenv('HUGGINGFACEHUB_API_TOKEN')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "14331eec-fd46-42e0-b6e7-adaf21824ef7",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "llm = OpenAI(temperature=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "0b7b772b",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "\n",
    "relevant_parts = []\n",
    "for p in Path(\".\").absolute().parts:\n",
    "    relevant_parts.append(p)\n",
    "    if relevant_parts[-3:] == [\"langchain\", \"docs\", \"modules\"]:\n",
    "        break\n",
    "doc_path = str(Path(*relevant_parts) / \"state_of_the_union.txt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "f2675861",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "loader = TextLoader(doc_path)\n",
    "documents = loader.load()\n",
    "text_splitter = CharacterTextSplitter(chunk_size=1000, chunk_overlap=0)\n",
    "texts = text_splitter.split_documents(documents)\n",
    "\n",
    "embeddings = OpenAIEmbeddings()\n",
    "docsearch = Chroma.from_documents(texts, embeddings, collection_name=\"state-of-union\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "bc5403d4",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "state_of_union = RetrievalQA.from_chain_type(\n",
    "    llm=llm, chain_type=\"stuff\", retriever=docsearch.as_retriever()\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "1431cded",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "USER_AGENT environment variable not set, consider setting it to identify your requests.\n"
     ]
    }
   ],
   "source": [
    "from langchain_community.document_loaders import WebBaseLoader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "915d3ff3",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "loader = WebBaseLoader(\"https://beta.ruff.rs/docs/faq/\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "96a2edf8",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Created a chunk of size 2134, which is longer than the specified 1000\n",
      "Created a chunk of size 2470, which is longer than the specified 1000\n",
      "Created a chunk of size 1259, which is longer than the specified 1000\n",
      "Created a chunk of size 1302, which is longer than the specified 1000\n"
     ]
    }
   ],
   "source": [
    "docs = loader.load()\n",
    "ruff_texts = text_splitter.split_documents(docs)\n",
    "ruff_db = Chroma.from_documents(ruff_texts, embeddings, collection_name=\"ruff\")\n",
    "ruff = RetrievalQA.from_chain_type(\n",
    "    llm=llm, chain_type=\"stuff\", retriever=ruff_db.as_retriever()\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c0a6c031",
   "metadata": {},
   "source": [
    "## Create the Agent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "eb142786",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Import things that are needed generically\n",
    "from langchain.agents import AgentType, Tool, initialize_agent\n",
    "from langchain_openai import OpenAI"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "850bc4e9",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "tools = [\n",
    "    Tool(\n",
    "        name=\"State of Union QA System\",\n",
    "        func=state_of_union.run,\n",
    "        description=\"useful for when you need to answer questions about the most recent state of the union address. Input should be a fully formed question.\",\n",
    "    ),\n",
    "    Tool(\n",
    "        name=\"Ruff QA System\",\n",
    "        func=ruff.run,\n",
    "        description=\"useful for when you need to answer questions about ruff (a python linter). Input should be a fully formed question.\",\n",
    "    ),\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "fc47f230",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Construct the agent. We will use the default agent type here.\n",
    "# See documentation for a full list of options.\n",
    "agent = initialize_agent(\n",
    "    tools, llm, agent=AgentType.ZERO_SHOT_REACT_DESCRIPTION, verbose=True\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "10ca2db8",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\u001b[1m> Entering new AgentExecutor chain...\u001b[0m\n",
      "\u001b[32;1m\u001b[1;3m I should use the State of Union QA System to answer this question.\n",
      "Action: State of Union QA System\n",
      "Action Input: \"What did Biden say about Ketanji Brown Jackson in the state of the union address?\"\u001b[0m\n",
      "Observation: \u001b[36;1m\u001b[1;3m Biden said that he nominated Ketanji Brown Jackson for the United States Supreme Court and praised her as one of the nation's top legal minds who will continue Justice Breyer's legacy of excellence.\u001b[0m\n",
      "Thought:\u001b[32;1m\u001b[1;3m I should use the Ruff QA System to get more information about Ketanji Brown Jackson.\n",
      "Action: Ruff QA System\n",
      "Action Input: \"Who is Ketanji Brown Jackson?\"\u001b[0m\n",
      "Observation: \u001b[33;1m\u001b[1;3m I don't know.\u001b[0m\n",
      "Thought:\u001b[32;1m\u001b[1;3m I should use the Ruff QA System to get more information about Ketanji Brown Jackson's background.\n",
      "Action: Ruff QA System\n",
      "Action Input: \"What is Ketanji Brown Jackson's background?\"\u001b[0m\n",
      "Observation: \u001b[33;1m\u001b[1;3m I don't know.\u001b[0m\n",
      "Thought:\u001b[32;1m\u001b[1;3m I should use the State of Union QA System to get more information about Ketanji Brown Jackson's nomination.\n",
      "Action: State of Union QA System\n",
      "Action Input: \"What is the status of Ketanji Brown Jackson's nomination?\"\u001b[0m\n",
      "Observation: \u001b[36;1m\u001b[1;3m Ketanji Brown Jackson has been nominated to serve on the United States Supreme Court and has received a broad range of support since her nomination.\u001b[0m\n",
      "Thought:\u001b[32;1m\u001b[1;3m I now know the final answer.\n",
      "Final Answer: Biden nominated Ketanji Brown Jackson for the United States Supreme Court and praised her as one of the nation's top legal minds who will continue Justice Breyer's legacy of excellence. Her nomination has received a broad range of support.\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'input': 'What did biden say about ketanji brown jackson in the state of the union address?',\n",
       " 'output': \"Biden nominated Ketanji Brown Jackson for the United States Supreme Court and praised her as one of the nation's top legal minds who will continue Justice Breyer's legacy of excellence. Her nomination has received a broad range of support.\"}"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "agent.invoke(\n",
    "    \"What did biden say about ketanji brown jackson in the state of the union address?\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "4e91b811",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\u001b[1m> Entering new AgentExecutor chain...\u001b[0m\n",
      "\u001b[32;1m\u001b[1;3m Ruff is a python linter that has some unique features compared to flake8, so it may be useful in certain situations.\n",
      "Action: Ruff QA System\n",
      "Action Input: \"Why use ruff over flake8?\"\u001b[0m\n",
      "Observation: \u001b[33;1m\u001b[1;3m Ruff can replace multiple Flake8 plugins, has a larger rule set, and can automatically fix its own lint violations. It also supports Python versions from 3.7 onwards and does not require the installation of Rust. Additionally, Ruff can be used independently as a linter or formatter, and can be used alongside a type checker for more comprehensive error detection.\u001b[0m\n",
      "Thought:\u001b[32;1m\u001b[1;3m This information is helpful, but I should also consider the specific needs of my project before deciding which linter to use.\n",
      "Action: State of Union QA System\n",
      "Action Input: \"What are the unique features of ruff compared to flake8?\"\u001b[0m\n",
      "Observation: \u001b[36;1m\u001b[1;3m I don't know.\u001b[0m\n",
      "Thought:\u001b[32;1m\u001b[1;3m I should ask a more specific question to get a better answer.\n",
      "Action: Ruff QA System\n",
      "Action Input: \"What are the specific features of ruff that make it stand out from flake8?\"\u001b[0m\n",
      "Observation: \u001b[33;1m\u001b[1;3m Ruff has over 800 rules, compared to Flake8's ~409 rules. Ruff also has the ability to replace popular Flake8 plugins, such as Black, isort, yesqa, eradicate, and most of the rules implemented in pyupgrade. Additionally, Ruff is capable of automatically fixing its own lint violations, unlike Flake8. However, Ruff does not support custom lint rules, unlike Flake8.\u001b[0m\n",
      "Thought:\u001b[32;1m\u001b[1;3m This information is helpful, but I should also consider the specific needs of my project before deciding which linter to use.\n",
      "Action: State of Union QA System\n",
      "Action Input: \"What are the specific needs of my project that I should consider when choosing between ruff and flake8?\"\u001b[0m\n",
      "Observation: \u001b[36;1m\u001b[1;3m I'm sorry, I cannot answer this question as it is not related to the context provided. The context is discussing inflation and the President's plan to address it. It does not mention anything about choosing between ruff and flake8 for a project.\u001b[0m\n",
      "Thought:\u001b[32;1m\u001b[1;3m I should ask a more relevant question to get a better answer.\n",
      "Action: Ruff QA System\n",
      "Action Input: \"What are the key differences between ruff and flake8 that I should consider when choosing a linter for my project?\"\u001b[0m\n",
      "Observation: \u001b[33;1m\u001b[1;3m\n",
      "1. Rule Set: Ruff implements over 800 rules, while Flake8 only implements around 400. Ruff also has a larger overlap with Pylint's rule set.\n",
      "\n",
      "2. Type Inference: Pylint does more type inference than Ruff, making it more suitable for projects that heavily rely on type checking.\n",
      "\n",
      "3. Custom Rules: Ruff does not support custom or third-party rules, while Flake8 does.\n",
      "\n",
      "4. Automatic Fixing: Ruff is capable of automatically fixing its own lint violations, while Flake8 does not have this feature.\n",
      "\n",
      "5. Try Blocks: Ruff's too-many-branches rule does not count try blocks as their own branches, unlike Flake8's R0912.\n",
      "\n",
      "6. Integration with Type Checkers: Ruff is recommended to be used alongside a type checker, while Flake8 does not have this integration.\n",
      "\n",
      "7. Black Compatibility: Ruff is designed to be used alongside a formatter like Black, while Flake8 does not have this integration.\n",
      "\n",
      "8. Python Versions: Ruff supports Python 3, while Flake8 supports both Python 2 and 3.\n",
      "\n",
      "9. Customization: Ruff uses different rule codes and prefixes than the originating Flake8 plugins, making it easier to toggle individual plugins on or\u001b[0m\n",
      "Thought:\u001b[32;1m\u001b[1;3m This information is helpful, but I should also consider the specific needs of my project before deciding which linter to use.\n",
      "Action: Ruff QA System\n",
      "Action Input: \"What are the specific needs of my project that I should consider when choosing between ruff and flake8?\"\u001b[0m\n",
      "Observation: \u001b[33;1m\u001b[1;3m Some specific needs to consider when choosing between ruff and flake8 are the compatibility with custom lint rules, support for specific Python versions, and compatibility with other tools like Black. Additionally, the project structure and line-length enforcement may also be factors to consider. It may be helpful to evaluate which rules and plugins are most important for your project and see if they are supported by both ruff and flake8.\u001b[0m\n",
      "Thought:\u001b[32;1m\u001b[1;3m I now know the final answer.\n",
      "Final Answer: When choosing between ruff and flake8, it is important to consider the specific needs of your project, such as compatibility with custom lint rules, support for specific Python versions, and compatibility with other tools. It may also be helpful to evaluate which rules and plugins are most important for your project and see if they are supported by both ruff and flake8.\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'input': 'Why use ruff over flake8?',\n",
       " 'output': 'When choosing between ruff and flake8, it is important to consider the specific needs of your project, such as compatibility with custom lint rules, support for specific Python versions, and compatibility with other tools. It may also be helpful to evaluate which rules and plugins are most important for your project and see if they are supported by both ruff and flake8.'}"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "agent.invoke(\"Why use ruff over flake8?\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "787a9b5e",
   "metadata": {},
   "source": [
    "## Use the Agent solely as a router"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9161ba91",
   "metadata": {},
   "source": [
    "You can also set `return_direct=True` if you intend to use the agent as a router and just want to directly return the result of the RetrievalQAChain.\n",
    "\n",
    "Notice that in the above examples the agent did some extra work after querying the RetrievalQAChain. You can avoid that and just return the result directly."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "f59b377e",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "tools = [\n",
    "    Tool(\n",
    "        name=\"State of Union QA System\",\n",
    "        func=state_of_union.run,\n",
    "        description=\"useful for when you need to answer questions about the most recent state of the union address. Input should be a fully formed question.\",\n",
    "        return_direct=True,\n",
    "    ),\n",
    "    Tool(\n",
    "        name=\"Ruff QA System\",\n",
    "        func=ruff.run,\n",
    "        description=\"useful for when you need to answer questions about ruff (a python linter). Input should be a fully formed question.\",\n",
    "        return_direct=True,\n",
    "    ),\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "8615707a",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "agent = initialize_agent(\n",
    "    tools, llm, agent=AgentType.ZERO_SHOT_REACT_DESCRIPTION, verbose=True\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "36e718a9",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\u001b[1m> Entering new AgentExecutor chain...\u001b[0m\n",
      "\u001b[32;1m\u001b[1;3m I should use the State of Union QA System to answer this question.\n",
      "Action: State of Union QA System\n",
      "Action Input: \"What did Biden say about Ketanji Brown Jackson in the state of the union address?\"\u001b[0m\n",
      "Observation: \u001b[36;1m\u001b[1;3m Biden said that he nominated Ketanji Brown Jackson for the United States Supreme Court and praised her as one of the nation's top legal minds who will continue Justice Breyer's legacy of excellence.\u001b[0m\n",
      "\u001b[32;1m\u001b[1;3m\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'input': 'What did biden say about ketanji brown jackson in the state of the union address?',\n",
       " 'output': \" Biden said that he nominated Ketanji Brown Jackson for the United States Supreme Court and praised her as one of the nation's top legal minds who will continue Justice Breyer's legacy of excellence.\"}"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "agent.invoke(\n",
    "    \"What did biden say about ketanji brown jackson in the state of the union address?\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "edfd0a1a",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\u001b[1m> Entering new AgentExecutor chain...\u001b[0m\n",
      "\u001b[32;1m\u001b[1;3m Ruff and flake8 are both python linters, so they have similar functions. However, there may be some differences that make one better than the other.\n",
      "Action: Ruff QA System\n",
      "Action Input: \"Why use ruff over flake8?\"\u001b[0m\n",
      "Observation: \u001b[33;1m\u001b[1;3m Ruff can replace multiple Flake8 plugins, has a larger rule set, and can automatically fix its own lint violations. It also supports Python versions from 3.7 onwards and does not require the installation of Rust. Additionally, Ruff can be used independently as a linter or formatter, and can be used alongside a type checker for more comprehensive error detection.\u001b[0m\n",
      "\u001b[32;1m\u001b[1;3m\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'input': 'Why use ruff over flake8?',\n",
       " 'output': ' Ruff can replace multiple Flake8 plugins, has a larger rule set, and can automatically fix its own lint violations. It also supports Python versions from 3.7 onwards and does not require the installation of Rust. Additionally, Ruff can be used independently as a linter or formatter, and can be used alongside a type checker for more comprehensive error detection.'}"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "agent.invoke(\"Why use ruff over flake8?\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "49a0cbbe",
   "metadata": {},
   "source": [
    "## Multi-Hop vector store reasoning\n",
    "\n",
    "Because vector stores are easily usable as tools in agents, it is easy to use answer multi-hop questions that depend on vector stores using the existing agent framework."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "d397a233",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "tools = [\n",
    "    Tool(\n",
    "        name=\"State of Union QA System\",\n",
    "        func=state_of_union.run,\n",
    "        description=\"useful for when you need to answer questions about the most recent state of the union address. Input should be a fully formed question, not referencing any obscure pronouns from the conversation before.\",\n",
    "    ),\n",
    "    Tool(\n",
    "        name=\"Ruff QA System\",\n",
    "        func=ruff.run,\n",
    "        description=\"useful for when you need to answer questions about ruff (a python linter). Input should be a fully formed question, not referencing any obscure pronouns from the conversation before.\",\n",
    "    ),\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "06157240",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Construct the agent. We will use the default agent type here.\n",
    "# See documentation for a full list of options.\n",
    "agent = initialize_agent(\n",
    "    tools, llm, agent=AgentType.ZERO_SHOT_REACT_DESCRIPTION, verbose=True\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "b492b520",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\u001b[1m> Entering new AgentExecutor chain...\u001b[0m\n",
      "\u001b[32;1m\u001b[1;3m I should check if the president mentioned any tools related to Jupyter Notebooks in the state of the union address.\n",
      "Action: State of Union QA System\n",
      "Action Input: \"What tools were mentioned in the state of the union address related to Jupyter Notebooks?\"\u001b[0m\n",
      "Observation: \u001b[36;1m\u001b[1;3m None.\u001b[0m\n",
      "Thought:\u001b[32;1m\u001b[1;3m I should check if ruff uses any tools to run over Jupyter Notebooks.\n",
      "Action: Ruff QA System\n",
      "Action Input: \"What tools does ruff use to run over Jupyter Notebooks?\"\u001b[0m\n",
      "Observation: \u001b[33;1m\u001b[1;3m Ruff integrates with nbQA, a tool for running linters and code formatters over Jupyter Notebooks.\u001b[0m\n",
      "Thought:\u001b[32;1m\u001b[1;3m I now know the final answer.\n",
      "Final Answer: Ruff uses nbQA to run over Jupyter Notebooks. The president did not mention this tool in the state of the union address.\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'input': 'What tool does ruff use to run over Jupyter Notebooks? Did the president mention that tool in the state of the union?',\n",
       " 'output': 'Ruff uses nbQA to run over Jupyter Notebooks. The president did not mention this tool in the state of the union address.'}"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "agent.invoke(\n",
    "    \"What tool does ruff use to run over Jupyter Notebooks? Did the president mention that tool in the state of the union?\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "474ab1b3-08d9-417e-a034-60a2142da3c1",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
